{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8094a0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T15:59:29.516929Z",
     "iopub.status.busy": "2025-12-11T15:59:29.516399Z",
     "iopub.status.idle": "2025-12-11T15:59:40.530472Z",
     "shell.execute_reply": "2025-12-11T15:59:40.529006Z"
    },
    "papermill": {
     "duration": 11.023045,
     "end_time": "2025-12-11T15:59:40.534171",
     "exception": false,
     "start_time": "2025-12-11T15:59:29.511126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ef-msu-2024-comp-3/sample-sub.ipynb\n",
      "/kaggle/input/ef-msu-2024-comp-3/archive/train.parquet\n",
      "/kaggle/input/ef-msu-2024-comp-3/archive/test.parquet\n",
      "                 event_time  product_id    brand    price    user_id  \\\n",
      "0   2019-11-01 00:06:33 UTC     1801881  samsung   488.80  455871375   \n",
      "1   2019-11-01 00:09:30 UTC     5100816   xiaomi    29.58  435497056   \n",
      "2   2019-11-01 00:10:12 UTC     1801881  samsung   488.80  455871375   \n",
      "3   2019-11-01 00:10:47 UTC     1005124    apple  1583.48  460335599   \n",
      "4   2019-11-01 00:11:15 UTC     1004856  samsung   128.42  411770392   \n",
      "5   2019-11-01 00:11:48 UTC     4100129     sony   462.79  414551692   \n",
      "6   2019-11-01 00:12:13 UTC     1801881  samsung   488.80  455871375   \n",
      "7   2019-11-01 00:13:10 UTC     1005129    apple  1337.23  416392109   \n",
      "8   2019-11-01 00:13:33 UTC     1002532    apple   532.57  464406759   \n",
      "9   2019-11-01 00:14:48 UTC     1801881  samsung   488.80  455871375   \n",
      "10  2019-11-01 00:15:10 UTC     1801881  samsung   488.80  414551692   \n",
      "11  2019-11-01 00:15:23 UTC     1005105    apple  1348.61  416965257   \n",
      "12  2019-11-01 00:16:06 UTC     1801881  samsung   488.80  455871375   \n",
      "13  2019-11-01 00:18:28 UTC     1801881  samsung   488.80  455871375   \n",
      "14  2019-11-01 00:19:37 UTC     1004873  samsung   362.29  414801724   \n",
      "\n",
      "                            user_session        cat_0       cat_1 cat_2 cat_3  \\\n",
      "0   4d76d6d3-fff5-4880-8327-e9e57b618e0e  electronics       video    tv    NA   \n",
      "1   c5a5ccdb-ed0b-4706-b25d-829f00441279           NA          NA    NA    NA   \n",
      "2   4d76d6d3-fff5-4880-8327-e9e57b618e0e  electronics       video    tv    NA   \n",
      "3   a58d94c8-c0d4-4f24-bf3c-04c4e69ea153  electronics  smartphone    NA    NA   \n",
      "4   61ceaf50-820a-4858-9a68-bab804d47a22  electronics  smartphone    NA    NA   \n",
      "5   ef4867dd-b922-4d92-abec-9a75acb2b769           NA          NA    NA    NA   \n",
      "6   4d76d6d3-fff5-4880-8327-e9e57b618e0e  electronics       video    tv    NA   \n",
      "7   61f913b1-ed5f-4495-8139-7e3e20be92c3  electronics  smartphone    NA    NA   \n",
      "8   21df43a6-be6a-44f6-b41c-c8fcbeb2e952  electronics  smartphone    NA    NA   \n",
      "9   4d76d6d3-fff5-4880-8327-e9e57b618e0e  electronics       video    tv    NA   \n",
      "10  ef4867dd-b922-4d92-abec-9a75acb2b769  electronics       video    tv    NA   \n",
      "11  ef3daa59-4936-43e5-a530-32902f64b2f4  electronics  smartphone    NA    NA   \n",
      "12  4d76d6d3-fff5-4880-8327-e9e57b618e0e  electronics       video    tv    NA   \n",
      "13  4d76d6d3-fff5-4880-8327-e9e57b618e0e  electronics       video    tv    NA   \n",
      "14  1083da5b-bead-49ea-8b5f-4f5eb3ff7cd2  electronics  smartphone    NA    NA   \n",
      "\n",
      "             timestamp  ts_hour  ts_minute  ts_weekday  ts_day  ts_month  \\\n",
      "0  2019-11-01 00:06:33        0          6           4       1        11   \n",
      "1  2019-11-01 00:09:30        0          9           4       1        11   \n",
      "2  2019-11-01 00:10:12        0         10           4       1        11   \n",
      "3  2019-11-01 00:10:47        0         10           4       1        11   \n",
      "4  2019-11-01 00:11:15        0         11           4       1        11   \n",
      "5  2019-11-01 00:11:48        0         11           4       1        11   \n",
      "6  2019-11-01 00:12:13        0         12           4       1        11   \n",
      "7  2019-11-01 00:13:10        0         13           4       1        11   \n",
      "8  2019-11-01 00:13:33        0         13           4       1        11   \n",
      "9  2019-11-01 00:14:48        0         14           4       1        11   \n",
      "10 2019-11-01 00:15:10        0         15           4       1        11   \n",
      "11 2019-11-01 00:15:23        0         15           4       1        11   \n",
      "12 2019-11-01 00:16:06        0         16           4       1        11   \n",
      "13 2019-11-01 00:18:28        0         18           4       1        11   \n",
      "14 2019-11-01 00:19:37        0         19           4       1        11   \n",
      "\n",
      "    ts_year  \n",
      "0      2019  \n",
      "1      2019  \n",
      "2      2019  \n",
      "3      2019  \n",
      "4      2019  \n",
      "5      2019  \n",
      "6      2019  \n",
      "7      2019  \n",
      "8      2019  \n",
      "9      2019  \n",
      "10     2019  \n",
      "11     2019  \n",
      "12     2019  \n",
      "13     2019  \n",
      "14     2019  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from catboost import CatBoostRanker, Pool\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from typing import Tuple\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "PATH_DATA = \"/kaggle/input/ef-msu-2024-comp-3/archive/\"\n",
    "\n",
    "df_train = pd.read_parquet(PATH_DATA + \"train.parquet\")\n",
    "df_test = pd.read_parquet(PATH_DATA + \"test.parquet\")\n",
    "print(df_train.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb17fa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T15:59:40.542922Z",
     "iopub.status.busy": "2025-12-11T15:59:40.542340Z",
     "iopub.status.idle": "2025-12-11T15:59:40.550637Z",
     "shell.execute_reply": "2025-12-11T15:59:40.548825Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015449,
     "end_time": "2025-12-11T15:59:40.553167",
     "exception": false,
     "start_time": "2025-12-11T15:59:40.537718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_date_k_weeks_before(cur_date: str, k: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Return date k weeks before cur_date in format YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    cur_date = datetime.datetime.strptime(cur_date, \"%Y-%m-%d\")\n",
    "    return (cur_date - datetime.timedelta(weeks=k)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def remove_duplicates_order(x: list) -> list:\n",
    "    \"\"\"\n",
    "    Removes duplicates from a list while preserving the order\n",
    "    \"\"\"\n",
    "    return list(dict.fromkeys(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361de45b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T15:59:40.562881Z",
     "iopub.status.busy": "2025-12-11T15:59:40.561693Z",
     "iopub.status.idle": "2025-12-11T15:59:40.569988Z",
     "shell.execute_reply": "2025-12-11T15:59:40.568752Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015902,
     "end_time": "2025-12-11T15:59:40.572336",
     "exception": false,
     "start_time": "2025-12-11T15:59:40.556434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_validation_split(df: pd.DataFrame, timestamp_to_split: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits the dataframe into train and validation sets\n",
    "    WARNING: Something might be missed here...\n",
    "    \"\"\"\n",
    "    data_train = df[df[\"timestamp\"] < timestamp_to_split]\n",
    "    val = df[df[\"timestamp\"] >= timestamp_to_split]\n",
    "\n",
    "    gt_val = val.groupby(\"user_id\")[[\"product_id\"]].agg(list).reset_index()\n",
    "    gt_val[\"product_id\"] = gt_val[\"product_id\"].apply(remove_duplicates_order)\n",
    "\n",
    "    timestamp_to_val_split = get_date_k_weeks_before(timestamp_to_split, k=2)\n",
    "    data_val = data_train[data_train[\"timestamp\"] >= timestamp_to_val_split]\n",
    "    data_train = data_train[data_train[\"timestamp\"] < timestamp_to_val_split].reset_index(drop=True)\n",
    "\n",
    "    gt_val = gt_val[gt_val[\"user_id\"].isin(set(data_val[\"user_id\"]))].reset_index(drop=True)\n",
    "    data_val = data_val[data_val[\"user_id\"].isin(set(gt_val[\"user_id\"]))].reset_index(drop=True)\n",
    "    return data_train, data_val, gt_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe2f30c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-11T15:59:40.581266Z",
     "iopub.status.busy": "2025-12-11T15:59:40.580884Z",
     "iopub.status.idle": "2025-12-11T15:59:46.899619Z",
     "shell.execute_reply": "2025-12-11T15:59:46.898406Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "papermill": {
     "duration": 6.327079,
     "end_time": "2025-12-11T15:59:46.902686",
     "exception": false,
     "start_time": "2025-12-11T15:59:40.575607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3090372, 17) (247187, 17) (44916, 2)\n",
      "                      event_time  product_id    brand    price    user_id  \\\n",
      "0        2019-11-01 00:06:33 UTC     1801881  samsung   488.80  455871375   \n",
      "1        2019-11-01 00:09:30 UTC     5100816   xiaomi    29.58  435497056   \n",
      "2        2019-11-01 00:10:12 UTC     1801881  samsung   488.80  455871375   \n",
      "3        2019-11-01 00:10:47 UTC     1005124    apple  1583.48  460335599   \n",
      "4        2019-11-01 00:11:15 UTC     1004856  samsung   128.42  411770392   \n",
      "...                          ...         ...      ...      ...        ...   \n",
      "3090367  2020-01-31 23:58:08 UTC   100013136       NA   305.03  412827824   \n",
      "3090368  2020-01-31 23:58:35 UTC     1004210  samsung    79.54  469886562   \n",
      "3090369  2020-01-31 23:58:39 UTC     5100562    apple   294.34  416974332   \n",
      "3090370  2020-01-31 23:59:39 UTC     1005186  samsung   720.46  498008011   \n",
      "3090371  2020-01-31 23:59:51 UTC     1004839     oppo   178.82  411474749   \n",
      "\n",
      "                                 user_session         cat_0        cat_1  \\\n",
      "0        4d76d6d3-fff5-4880-8327-e9e57b618e0e   electronics        video   \n",
      "1        c5a5ccdb-ed0b-4706-b25d-829f00441279            NA           NA   \n",
      "2        4d76d6d3-fff5-4880-8327-e9e57b618e0e   electronics        video   \n",
      "3        a58d94c8-c0d4-4f24-bf3c-04c4e69ea153   electronics   smartphone   \n",
      "4        61ceaf50-820a-4858-9a68-bab804d47a22   electronics   smartphone   \n",
      "...                                       ...           ...          ...   \n",
      "3090367  c28543ae-3cd1-4fda-ac2e-8a6c6d16ae65          auto  accessories   \n",
      "3090368  9c495f7f-e0a7-49be-8ac0-1a6383234875  construction        tools   \n",
      "3090369  13e7a25f-90cb-45e9-baf0-a94e1f90628e   electronics       clocks   \n",
      "3090370  8f221a6b-20c4-43c1-a1c6-cb1b1f189efe    appliances      kitchen   \n",
      "3090371  ad43fda6-0401-4bc6-b5a5-f045906c197e  construction        tools   \n",
      "\n",
      "                 cat_2 cat_3           timestamp  ts_hour  ts_minute  \\\n",
      "0                   tv    NA 2019-11-01 00:06:33        0          6   \n",
      "1                   NA    NA 2019-11-01 00:09:30        0          9   \n",
      "2                   tv    NA 2019-11-01 00:10:12        0         10   \n",
      "3                   NA    NA 2019-11-01 00:10:47        0         10   \n",
      "4                   NA    NA 2019-11-01 00:11:15        0         11   \n",
      "...                ...   ...                 ...      ...        ...   \n",
      "3090367     compressor    NA 2020-01-31 23:58:08       23         58   \n",
      "3090368          light    NA 2020-01-31 23:58:35       23         58   \n",
      "3090369             NA    NA 2020-01-31 23:58:39       23         58   \n",
      "3090370  refrigerators    NA 2020-01-31 23:59:39       23         59   \n",
      "3090371          light    NA 2020-01-31 23:59:51       23         59   \n",
      "\n",
      "         ts_weekday  ts_day  ts_month  ts_year  \n",
      "0                 4       1        11     2019  \n",
      "1                 4       1        11     2019  \n",
      "2                 4       1        11     2019  \n",
      "3                 4       1        11     2019  \n",
      "4                 4       1        11     2019  \n",
      "...             ...     ...       ...      ...  \n",
      "3090367           4      31         1     2020  \n",
      "3090368           4      31         1     2020  \n",
      "3090369           4      31         1     2020  \n",
      "3090370           4      31         1     2020  \n",
      "3090371           4      31         1     2020  \n",
      "\n",
      "[3090372 rows x 17 columns]\n",
      "                     event_time  product_id       brand   price    user_id  \\\n",
      "0       2020-02-02 00:02:48 UTC    57700001          NA    3.73  499063394   \n",
      "1       2020-02-02 00:03:11 UTC   100007907    kingston  116.13  410859665   \n",
      "2       2020-02-02 00:03:12 UTC   100073651  aquamarine   12.74  495869706   \n",
      "3       2020-02-02 00:03:54 UTC     4804056       apple  149.22  451087290   \n",
      "4       2020-02-02 00:04:28 UTC   100040151          NA    7.59  499063394   \n",
      "...                         ...         ...         ...     ...        ...   \n",
      "247182  2020-02-15 23:58:21 UTC     1005015     samsung  501.89  488257550   \n",
      "247183  2020-02-15 23:58:23 UTC     1004226       apple  769.39  497195711   \n",
      "247184  2020-02-15 23:58:23 UTC     1004226       apple  769.39  497195711   \n",
      "247185  2020-02-15 23:58:37 UTC    21406425        dkny  180.18  509119119   \n",
      "247186  2020-02-15 23:58:38 UTC    21406425        dkny  180.18  509119119   \n",
      "\n",
      "                                user_session         cat_0    cat_1    cat_2  \\\n",
      "0       57ea6074-4e46-4d44-abfe-78766ac8be3c         sport  trainer       NA   \n",
      "1       0c45fc40-5a00-4261-b10e-f766d96c8098       apparel    shoes  slipons   \n",
      "2       fc54275d-b25b-43ea-a284-566076d8a7c4     furniture  bedroom  blanket   \n",
      "3       cb122d3d-76ac-43e4-8851-b236fef60680         sport  bicycle       NA   \n",
      "4       57ea6074-4e46-4d44-abfe-78766ac8be3c       apparel    shirt       NA   \n",
      "...                                      ...           ...      ...      ...   \n",
      "247182  37b35f5d-ce30-4876-981a-744b14b1eeeb  construction    tools    light   \n",
      "247183  7f0cf2cf-4307-4e16-9da1-ced7e410d0fc  construction    tools    light   \n",
      "247184  7f0cf2cf-4307-4e16-9da1-ced7e410d0fc  construction    tools    light   \n",
      "247185  ba4d9cce-adde-4bce-9938-dc25cc0de698   electronics   clocks       NA   \n",
      "247186  ba4d9cce-adde-4bce-9938-dc25cc0de698   electronics   clocks       NA   \n",
      "\n",
      "       cat_3           timestamp  ts_hour  ts_minute  ts_weekday  ts_day  \\\n",
      "0         NA 2020-02-02 00:02:48        0          2           6       2   \n",
      "1         NA 2020-02-02 00:03:11        0          3           6       2   \n",
      "2         NA 2020-02-02 00:03:12        0          3           6       2   \n",
      "3         NA 2020-02-02 00:03:54        0          3           6       2   \n",
      "4         NA 2020-02-02 00:04:28        0          4           6       2   \n",
      "...      ...                 ...      ...        ...         ...     ...   \n",
      "247182    NA 2020-02-15 23:58:21       23         58           5      15   \n",
      "247183    NA 2020-02-15 23:58:23       23         58           5      15   \n",
      "247184    NA 2020-02-15 23:58:23       23         58           5      15   \n",
      "247185    NA 2020-02-15 23:58:37       23         58           5      15   \n",
      "247186    NA 2020-02-15 23:58:38       23         58           5      15   \n",
      "\n",
      "        ts_month  ts_year  \n",
      "0              2     2020  \n",
      "1              2     2020  \n",
      "2              2     2020  \n",
      "3              2     2020  \n",
      "4              2     2020  \n",
      "...          ...      ...  \n",
      "247182         2     2020  \n",
      "247183         2     2020  \n",
      "247184         2     2020  \n",
      "247185         2     2020  \n",
      "247186         2     2020  \n",
      "\n",
      "[247187 rows x 17 columns]\n",
      "CPU times: user 5.55 s, sys: 730 ms, total: 6.28 s\n",
      "Wall time: 6.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_train, data_val, gt_val = get_validation_split(df=df_train, timestamp_to_split=\"2020-02-16\")\n",
    "print(data_train.shape, data_val.shape, gt_val.shape)\n",
    "print(data_train)\n",
    "print(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a90def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T15:59:46.912264Z",
     "iopub.status.busy": "2025-12-11T15:59:46.911889Z",
     "iopub.status.idle": "2025-12-11T15:59:46.919209Z",
     "shell.execute_reply": "2025-12-11T15:59:46.918003Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015418,
     "end_time": "2025-12-11T15:59:46.921538",
     "exception": false,
     "start_time": "2025-12-11T15:59:46.906120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "        A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "        A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "        The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if actual is None or len(actual) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        # first condition checks whether it is valid prediction\n",
    "        # second condition checks if prediction is not repeated\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d680b1af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T15:59:46.930133Z",
     "iopub.status.busy": "2025-12-11T15:59:46.929682Z",
     "iopub.status.idle": "2025-12-11T15:59:46.935657Z",
     "shell.execute_reply": "2025-12-11T15:59:46.934412Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015241,
     "end_time": "2025-12-11T15:59:46.940295",
     "exception": false,
     "start_time": "2025-12-11T15:59:46.925054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f1f15d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T15:59:46.953685Z",
     "iopub.status.busy": "2025-12-11T15:59:46.952660Z",
     "iopub.status.idle": "2025-12-11T16:00:34.613957Z",
     "shell.execute_reply": "2025-12-11T16:00:34.612163Z"
    },
    "papermill": {
     "duration": 47.671119,
     "end_time": "2025-12-11T16:00:34.616207",
     "exception": false,
     "start_time": "2025-12-11T15:59:46.945088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36169/36169 [00:18<00:00, 1952.96it/s]\n",
      "100%|██████████| 36169/36169 [00:17<00:00, 2035.24it/s]\n",
      "  4%|▍         | 1388/36169 [00:00<00:05, 6930.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1005100, 1004767, 100068488]\n",
      "[  1005100   1004767 100068488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36169/36169 [00:06<00:00, 5631.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>count</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005115</td>\n",
       "      <td>3849</td>\n",
       "      <td>apple</td>\n",
       "      <td>872.09</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>1005100</td>\n",
       "      <td>3205</td>\n",
       "      <td>samsung</td>\n",
       "      <td>146.01</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7054</th>\n",
       "      <td>1004767</td>\n",
       "      <td>3087</td>\n",
       "      <td>samsung</td>\n",
       "      <td>241.83</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10141</th>\n",
       "      <td>1002544</td>\n",
       "      <td>2790</td>\n",
       "      <td>apple</td>\n",
       "      <td>397.10</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12931</th>\n",
       "      <td>100068488</td>\n",
       "      <td>2532</td>\n",
       "      <td>samsung</td>\n",
       "      <td>293.06</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57208</th>\n",
       "      <td>1002525</td>\n",
       "      <td>166</td>\n",
       "      <td>apple</td>\n",
       "      <td>591.78</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57374</th>\n",
       "      <td>1005203</td>\n",
       "      <td>163</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>110.43</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57537</th>\n",
       "      <td>5100503</td>\n",
       "      <td>162</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>22.49</td>\n",
       "      <td>shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57699</th>\n",
       "      <td>1005121</td>\n",
       "      <td>161</td>\n",
       "      <td>apple</td>\n",
       "      <td>872.61</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57860</th>\n",
       "      <td>1004886</td>\n",
       "      <td>159</td>\n",
       "      <td>oppo</td>\n",
       "      <td>140.29</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  count    brand   price  cat_1\n",
       "0         1005115   3849    apple  872.09  tools\n",
       "3849      1005100   3205  samsung  146.01  tools\n",
       "7054      1004767   3087  samsung  241.83  tools\n",
       "10141     1002544   2790    apple  397.10  tools\n",
       "12931   100068488   2532  samsung  293.06  tools\n",
       "...           ...    ...      ...     ...    ...\n",
       "57208     1002525    166    apple  591.78  tools\n",
       "57374     1005203    163   xiaomi  110.43  tools\n",
       "57537     5100503    162   xiaomi   22.49  shoes\n",
       "57699     1005121    161    apple  872.61  tools\n",
       "57860     1004886    159     oppo  140.29  tools\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['price'] = pd.to_numeric(data_train['price'])\n",
    "df_test['price'] = pd.to_numeric(df_test['price'])\n",
    "\n",
    "popular_from_train = data_train.groupby([\"product_id\"])[[\"event_time\"]].count().reset_index().sort_values(by=\"event_time\", ascending=False).rename(columns={\"event_time\": \"count\"})\n",
    "name = 'timestamp'\n",
    "popular_from_test = df_test.groupby([\"product_id\"])[[name]].count().reset_index().sort_values(by=name, ascending=False).rename(columns={name: \"count\"})\n",
    "pop_brand = pd.merge(popular_from_test, df_test[['product_id', 'brand', 'price', 'cat_1']], on='product_id', how='left').drop_duplicates(subset='product_id')\n",
    "np.array(Counter(df_test[['user_id', 'brand']].values[:, 1]).most_common(3))[:, 0]\n",
    "users_brands = pd.pivot_table(df_test, \n",
    "               index=['user_id'],\n",
    "                values=['brand'],\n",
    "                aggfunc=lambda x: np.array(Counter(x).most_common(3,))[:, 0])\n",
    "user_brands = {key:value for key, value in users_brands.reset_index().values}\n",
    "users_price = pd.pivot_table(df_test, \n",
    "               index=['user_id'],\n",
    "                values=['price'],\n",
    "                aggfunc='mean')\n",
    "users_price = {key:value for key, value in users_price.reset_index().values}\n",
    "df_user_brands = df_test.groupby([\"user_id\"])[[name]].count().reset_index().sort_values(by=name, ascending=False).rename(columns={name: \"count\"})\n",
    "item_brands = {key:value for key, value in pop_brand[['product_id', 'brand']].values}\n",
    "item_price = {key:float(value) for key, value in pop_brand[['product_id', 'price']].values}\n",
    "\n",
    "mapk(actual=gt_val[\"product_id\"].to_list(), predicted=[popular_from_train.head(10)[\"product_id\"].to_list() for _ in range(len(gt_val))], k=10)\n",
    "\n",
    "\n",
    "dict_bought = {}\n",
    "test_users = df_test[[\"user_id\"]].drop_duplicates()['user_id'].values\n",
    "df_bought = df_test[['user_id', 'product_id']]\n",
    "for user in tqdm(test_users):\n",
    "    dict_bought[user] = np.unique(df_bought[df_bought['user_id']==user]['product_id'].values)\n",
    "\n",
    "ids = np.array([])\n",
    "for user in tqdm(test_users):\n",
    "    ids = np.append(ids, [item for item in popular_from_test['product_id'].values[:60] if item not in dict_bought[user]][:10])\n",
    "ids = ids.reshape(-1, 10).astype(int)\n",
    "pers_top_3 = np.array([])\n",
    "i = 0\n",
    "for user in tqdm(test_users):\n",
    "    pers_brand = [item for item in ids[i] if ((item_brands[item] in user_brands[user]) & (item_price[item] > 0.35*users_price[user]) & (item_price[item] < 2.4*users_price[user])).all()  ] [:3]\n",
    "    rec = np.append(pers_brand, popular_from_test['product_id'].values[:3])[:3]\n",
    "    pers_top_3 = np.append(pers_top_3, rec)\n",
    "    if i == 1:\n",
    "        print(pers_brand)\n",
    "        print(rec)\n",
    "    i += 1\n",
    "\n",
    "pers_top_3 = pers_top_3.reshape(-1, 3)\n",
    "pers_top_3.astype(int)\n",
    "\n",
    "df_test[df_test['user_id']==test_users[1]]\n",
    "pop_brand[pop_brand['brand']==user_brands[test_users[0]][0]]\n",
    "pop_brand.iloc[:100, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b9477c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T16:00:34.671713Z",
     "iopub.status.busy": "2025-12-11T16:00:34.671359Z",
     "iopub.status.idle": "2025-12-11T16:00:34.821381Z",
     "shell.execute_reply": "2025-12-11T16:00:34.820325Z"
    },
    "papermill": {
     "duration": 0.180003,
     "end_time": "2025-12-11T16:00:34.824011",
     "exception": false,
     "start_time": "2025-12-11T16:00:34.644008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(test_users, columns=['user_id'])\n",
    "df_sub[\"product_id\"] = list(map(lambda x: \" \".join(map(str, x)), pers_top_3.astype(int)))\n",
    "df_sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "#df_sub = df_test[[\"user_id\"]].drop_duplicates()\n",
    "#df_sub[\"product_id\"] = [popular_from_train.head(10)[\"product_id\"].to_list() for _ in range(len(df_sub))]\n",
    "#df_sub[\"product_id\"] = df_sub[\"product_id\"].apply(lambda x: \" \".join(map(str, x)))\n",
    "#df_sub\n",
    "#df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10375960,
     "sourceId": 89765,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.859172,
   "end_time": "2025-12-11T16:00:36.075263",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-11T15:59:26.216091",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
